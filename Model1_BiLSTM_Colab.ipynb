{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac5d84d",
   "metadata": {},
   "source": [
    "# Model 1: Siamese BiLSTM for Natural Language Inference - Google Colab Version\n",
    "\n",
    "Binary classification: entails (0) vs neutral (1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if running on colab and gpu availability\n",
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab\")\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: GPU not detected!\")\n",
    "    print(\"Please enable GPU: Runtime → Change runtime type → Hardware accelerator → GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c2db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload preprocessed data file\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"Please upload your preprocessed_data.pkl file:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if 'preprocessed_data.pkl' in uploaded:\n",
    "        print(f\"✓ Successfully uploaded preprocessed_data.pkl ({len(uploaded['preprocessed_data.pkl']) / 1e6:.2f} MB)\")\n",
    "    else:\n",
    "        print(\"❌ Error: preprocessed_data.pkl not found. Please upload it.\")\n",
    "else:\n",
    "    # assume file is in current directory when not on colab\n",
    "    if os.path.exists('preprocessed_data.pkl'):\n",
    "        print(\"✓ preprocessed_data.pkl found in current directory\")\n",
    "    else:\n",
    "        print(\"❌ Error: preprocessed_data.pkl not found in current directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional imports\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✓ All packages imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc6e94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✓ Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    print(\"  No GPU available, training will be slower\")\n",
    "    USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b926cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 23088\n",
      "Validation examples: 1304\n",
      "Test examples: 2126\n",
      "Vocabulary size: 20499\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed data\n",
    "with open('preprocessed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_premise_idx = data['train_premise_idx']\n",
    "train_hypothesis_idx = data['train_hypothesis_idx']\n",
    "train_labels = data['train_labels']\n",
    "\n",
    "test_premise_idx = data['test_premise_idx']\n",
    "test_hypothesis_idx = data['test_hypothesis_idx']\n",
    "test_labels = data['test_labels']\n",
    "\n",
    "val_premise_idx = data['val_premise_idx']\n",
    "val_hypothesis_idx = data['val_hypothesis_idx']\n",
    "val_labels = data['val_labels']\n",
    "\n",
    "word_to_ix = data['word_to_ix']\n",
    "vocab_size = data['vocab_size']\n",
    "label_to_ix = data['label_to_ix']\n",
    "ix_to_label = data['ix_to_label']\n",
    "\n",
    "print(f\"Training examples: {len(train_premise_idx)}\")\n",
    "print(f\"Validation examples: {len(val_premise_idx)}\")\n",
    "print(f\"Test examples: {len(test_premise_idx)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sequence length statistics\n",
    "premise_lens = [len(p) for p in train_premise_idx]\n",
    "hyp_lens = [len(h) for h in train_hypothesis_idx]\n",
    "\n",
    "print(f\"Premise lengths - Max: {max(premise_lens)}, Mean: {np.mean(premise_lens):.1f}, 95th percentile: {np.percentile(premise_lens, 95):.1f}\")\n",
    "print(f\"Hypothesis lengths - Max: {max(hyp_lens)}, Mean: {np.mean(hyp_lens):.1f}, 95th percentile: {np.percentile(hyp_lens, 95):.1f}\")\n",
    "print(f\"\\nNote: Sequences will be truncated to {200} tokens to manage memory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb7bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class\n",
    "class NLIDataset(Dataset):\n",
    "    def __init__(self, premise_idx, hypothesis_idx, labels):\n",
    "        self.premise_idx = premise_idx\n",
    "        self.hypothesis_idx = hypothesis_idx\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'premise': self.premise_idx[idx],\n",
    "            'hypothesis': self.hypothesis_idx[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate function for padding with length limiting\n",
    "MAX_SEQ_LENGTH = 200  # limit sequence length to prevent memory issues\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # extract sequences and labels\n",
    "    premises = [item['premise'] for item in batch]\n",
    "    hypotheses = [item['hypothesis'] for item in batch]\n",
    "    labels = [item['label'] for item in batch]\n",
    "    \n",
    "    # truncate sequences if too long\n",
    "    premises = [p[:MAX_SEQ_LENGTH] for p in premises]\n",
    "    hypotheses = [h[:MAX_SEQ_LENGTH] for h in hypotheses]\n",
    "    \n",
    "    # get max lengths in this batch\n",
    "    max_premise_len = max(len(p) for p in premises)\n",
    "    max_hypothesis_len = max(len(h) for h in hypotheses)\n",
    "    \n",
    "    # pad sequences\n",
    "    padded_premises = []\n",
    "    for p in premises:\n",
    "        padded = p + [0] * (max_premise_len - len(p))\n",
    "        padded_premises.append(padded)\n",
    "    \n",
    "    padded_hypotheses = []\n",
    "    for h in hypotheses:\n",
    "        padded = h + [0] * (max_hypothesis_len - len(h))\n",
    "        padded_hypotheses.append(padded)\n",
    "    \n",
    "    # convert to tensors\n",
    "    premises_tensor = torch.LongTensor(padded_premises)\n",
    "    hypotheses_tensor = torch.LongTensor(padded_hypotheses)\n",
    "    labels_tensor = torch.LongTensor(labels)\n",
    "    \n",
    "    return premises_tensor, hypotheses_tensor, labels_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 361\n",
      "Number of validation batches: 21\n",
      "Number of test batches: 34\n"
     ]
    }
   ],
   "source": [
    "# create datasets\n",
    "train_dataset = NLIDataset(train_premise_idx, train_hypothesis_idx, train_labels)\n",
    "val_dataset = NLIDataset(val_premise_idx, val_hypothesis_idx, val_labels)\n",
    "test_dataset = NLIDataset(test_premise_idx, test_hypothesis_idx, test_labels)\n",
    "\n",
    "# hyperparameters - automatically adjust batch size based on GPU\n",
    "BATCH_SIZE = 64 if USE_GPU else 32  # use 64 for GPU, 32 for CPU\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Embedding dim: {EMBEDDING_DIM}\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Number of epochs: {NUM_EPOCHS}\")\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"\\nDataloaders created:\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589ca682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese bilstm model\n",
    "class SiameseBiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(SiameseBiLSTM, self).__init__()\n",
    "        \n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # bidirectional lstm\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # classification layers\n",
    "        self.fc1 = nn.Linear(4 * hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # embed sequence\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        # pass through bilstm\n",
    "        lstm_out, (h_n, c_n) = self.lstm(embeds)\n",
    "        \n",
    "        # concat forward and backward final hidden states\n",
    "        hidden = torch.cat((h_n[0], h_n[1]), dim=1)\n",
    "        return hidden\n",
    "    \n",
    "    def forward(self, premise, hypothesis):\n",
    "        # encode both sequences with shared encoder\n",
    "        premise_vec = self.encode(premise)\n",
    "        hypothesis_vec = self.encode(hypothesis)\n",
    "        \n",
    "        # concatenate encodings\n",
    "        combined = torch.cat((premise_vec, hypothesis_vec), dim=1)\n",
    "        \n",
    "        # classification\n",
    "        out = torch.relu(self.fc1(combined))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f371471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n",
      "Total parameters: 3677314\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = SiameseBiLSTM(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"Model initialized\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bbfea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for premises, hypotheses, labels in dataloader:\n",
    "        premises = premises.to(device)\n",
    "        hypotheses = hypotheses.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(premises, hypotheses)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # get predictions\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b4070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for premises, hypotheses, labels in dataloader:\n",
    "            premises = premises.to(device)\n",
    "            hypotheses = hypotheses.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(premises, hypotheses)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "best_val_acc = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_siamese_bilstm.pth')\n",
    "        print(f\"Best model saved with validation accuracy: {best_val_acc:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model.load_state_dict(torch.load('best_siamese_bilstm.pth'))\n",
    "print(\"Best model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f23786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "test_loss, test_acc, test_preds, test_labels = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=['entails', 'neutral']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c304f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# plot loss\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# plot accuracy\n",
    "ax2.plot(train_accs, label='Train Acc')\n",
    "ax2.plot(val_accs, label='Val Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training results\n",
    "results = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_accs': train_accs,\n",
    "    'val_accs': val_accs,\n",
    "    'test_loss': test_loss,\n",
    "    'test_acc': test_acc,\n",
    "    'hyperparameters': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'num_epochs': NUM_EPOCHS\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('bilstm_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(\"Results saved to bilstm_results.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66947fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download trained model and results\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"Downloading trained model and results...\")\n",
    "    \n",
    "    # download the best model\n",
    "    if os.path.exists('best_siamese_bilstm.pth'):\n",
    "        files.download('best_siamese_bilstm.pth')\n",
    "        print(\"Downloaded: best_siamese_bilstm.pth\")\n",
    "    else:\n",
    "        print(\"Error: best_siamese_bilstm.pth not found\")\n",
    "    \n",
    "    # download the results\n",
    "    if os.path.exists('bilstm_results.pkl'):\n",
    "        files.download('bilstm_results.pkl')\n",
    "        print(\"Downloaded: bilstm_results.pkl\")\n",
    "    else:\n",
    "        print(\"Error: bilstm_results.pkl not found\")\n",
    "    \n",
    "    print(\"All files downloaded! You can now test the model locally.\")\n",
    "else:\n",
    "    print(\"Not running on Colab - files are already in your local directory\")\n",
    "    print(f\"  Model: best_siamese_bilstm.pth\")\n",
    "    print(f\"  Results: bilstm_results.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
